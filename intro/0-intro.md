## Machine learning 

Machine learning is a branch of artificial intelligence where computers learn patterns from data to make predictions or decisions without being explicitly programmed for every scenario.

### use cases:
- spam filter
- voice assistant 
- recommendation systems 
....more

### Key Learning Paradigms
- Supervised Learning: Trains on labeled data to predict outcomes, like classifying emails as spam or not.
- Unsupervised Learning: Finds patterns in unlabeled data, such as clustering customers by behavior.
- Reinforcement Learning: Learns via trial-and-error rewards, powering game AI or robotics.

### Essential Components
- Data: Fuel for models; split into training, validation, and test sets to avoid overfitting.
- Features and Labels: Input variables (features) and target outputs (labels) define what the model learns.
- Models: Mathematical representations, from simple linear regression to complex neural networks.
​
### Training Process
- Optimization: Adjusts model parameters (e.g., via gradient descent) to minimize prediction errors.
- Loss Function: Measures how wrong predictions are, guiding improvements.
- Hyperparameters: Settings like learning rate, tuned for best performance.
​
### Machine learning workflow visualized
Data Collection → Data Preparation → Data Splitting → Model Selection & Training → Evaluation & Tuning → Deployment → Monitoring & Retraining


### Essential Algorithms
- Linear Regression: 
Predicts continuous values; simple for trends like house prices.
- Logistic Regression: 
Binary/multiclass classification; fast for spam detection.
- Decision Trees: 
Interpretable splits for classification/regression; prone to overfitting.
- Random Forest: 
Ensemble of trees; robust, handles missing data well.
- k-Nearest Neighbors (k-NN): 
Instance-based; classifies via nearest examples.
- Support Vector Machines (SVM): 
Finds optimal hyperplane; strong for high-dimensional data.
- Gradient Boosting (XGBoost, LightGBM, CatBoost): 
Tops benchmarks for tabular data; excels in competitions.
- K-Means: 
Unsupervised clustering; groups similar data points.
- Naive Bayes: Probabilistic; efficient for text/spam filtering.
​

### Popular Libraries
- Pandas/NumPy: 
Data prep – Essential preprocessing.
- scikit-learn: 
Classical ML (regression, trees) – Beginner-friendly, comprehensive.
- TensorFlow/Keras: 
Deep learning – Scalable neural nets.
- PyTorch: 
Research/flexible DL – Dynamic graphs, GPU support.
- XGBoost/LightGBM: 
Boosting on tabular data – Competition winners.